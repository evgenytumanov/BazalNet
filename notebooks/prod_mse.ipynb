{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:\n",
      "b'C:\\\\Users\\\\tumanov\\\\AppData\\\\Local\\\\Temp\\\\try_flags_rfq1z6g_.c:4:19: fatal error: cudnn.h: No such file or directory\\r\\ncompilation terminated.\\r\\n'\n",
      "Mapped name None to device cuda0: GeForce GTX 1070 (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def non_trainable(net):\n",
    "    for tags in net.params.values():\n",
    "        tags -= {'trainable', 'regularizable'}\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(size, digits, problem = lambda a, b: a+b, problem_operator='{}+{}'):\n",
    "    source_seqs = []\n",
    "    target_seqs = []\n",
    "    seen = set()\n",
    "    print('Generating data...')\n",
    "    while len(source_seqs) < TRAINING_SIZE:\n",
    "        f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                        for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "        a, b = f(), f()\n",
    "        # Skip any addition questions we've already seen\n",
    "        # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "        key = tuple(sorted((a, b)))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        # Pad the data with spaces such that it is always MAXLEN.\n",
    "        q = problem_operator.format(a, b)\n",
    "        ans = problem(a, b)\n",
    "\n",
    "        source_seqs.append(q)\n",
    "        targes.append(ans)\n",
    "\n",
    "    print('Total addition questions:', len(source_seqs))\n",
    "    \n",
    "    source_letters = list(set([token for word in source_seqs for token in word]))\n",
    "    source_letter_to_ix = {l:i for i,l in enumerate(source_letters)}\n",
    "    \n",
    "    return np.array(source_seqs), source_letters, source_letter_to_ix, np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_matrix(sequences, token_to_i, max_len=None, PAX_ix=-1):\n",
    "    \"\"\"\n",
    "    Converts several sequences of tokens to a matrix, edible a neural network.\n",
    "    Crops at max_len(if given), pads shorter sequences with -1 or PAD_ix.\n",
    "    \"\"\"\n",
    "    max_len = max_len or max(map(len,sequences))\n",
    "    \n",
    "    matrix = np.zeros((len(sequences),max_len),dtype='int8') -1\n",
    "    for i,seq in enumerate(sequences):\n",
    "        \n",
    "        row_ix = [token_to_i.get(_, 0) for _ in seq[:max_len]]\n",
    "        matrix[i,:len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('token sequence', 'int32')\n",
    "output_sequence = T.matrix('target target_letters', 'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_model(nn, learning_rate=0.001):\n",
    "    # Model weights\n",
    "    weights = get_all_params(nn)\n",
    "    network_output = get_output(nn)\n",
    "\n",
    "    predictions_flat = network_output[:,:-1,:].reshape([-1,len(target_letters)])\n",
    "    targets = output_sequence[:,1:].ravel()\n",
    "\n",
    "    #do not count loss for '-1' tokens\n",
    "    mask = T.nonzero(T.neq(targets,-1))\n",
    "\n",
    "    loss = lasagne.objectives.categorical_crossentropy(predictions_flat[mask], targets[mask]).mean()\n",
    "    updates = lasagne.updates.adam(loss, weights, learning_rate=learning_rate)\n",
    "    #training\n",
    "    train = theano.function([input_sequence, output_sequence], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "    #computing loss without training\n",
    "    compute_cost = theano.function([input_sequence, output_sequence], loss, allow_input_downcast=True)\n",
    "    #compile the function that computes probabilities for next token given previous text.\n",
    "\n",
    "    last_probas =network_output[:, -1]\n",
    "\n",
    "    probs = theano.function([input_sequence, output_sequence], last_probas)\n",
    "    return train, compute_cost, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CerMemory(lasagne.layers.Layer):\n",
    "    def __init__(self, incoming, memory_size, M=lasagne.init.Orthogonal(), **kwargs):\n",
    "        super(CerMemory, self).__init__(incoming, **kwargs)\n",
    "        self.query_shape = self.input_shape[1]\n",
    "        self.memory_size = memory_size\n",
    "        self.M = self.add_param(M, (self.query_shape, memory_size), name='M')\n",
    "\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        m = self.M / T.sqrt(T.sqr(self.M).sum(axis=0)).reshape(self.M.shape[1], 1)\n",
    "        weights =  T.dot(input, m)\n",
    "        return T.dot(weights, m.T)\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.query_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EvcNormalizer(lasagne.layers.Layer):\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        return (input.T / T.sqrt(T.sqr(input).sum(axis=1)).reshape(input.shape[0], 1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bazal_model(query_size, memory_size, hidden_size, memory_benchmark=False, bidir_features=False):\n",
    "\n",
    "    ##ENCODER\n",
    "    l_in = InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "    l_mask = InputLayer(shape=(None, None),input_var=T.neq(input_sequence,-1)) \n",
    "\n",
    "\n",
    "    l_emb = non_trainable(EmbeddingLayer(l_in, len(source_letters),  len(source_letters), W=np.diag(np.ones(len(source_letters)))))\n",
    "\n",
    "    features = LSTMLayer(l_emb, HIDDEN_SIZE, only_return_final=True, mask_input=l_mask)\n",
    "    features_backward = LSTMLayer(l_emb, HIDDEN_SIZE, only_return_final=True, mask_input=l_mask, backwards=True)\n",
    "    if bidir_features:\n",
    "        features = ConcatLayer([features, features_backward])\n",
    "    \n",
    "    if not memory_benchmark:\n",
    "        ## QUERY BUILDER\n",
    "        query = DenseLayer(features, QUERY_SIZE, nonlinearity=None)\n",
    "        query = EvcNormalizer(query)\n",
    "        ## Memory\n",
    "        memory = CerMemory(query, MEMORY_SIZE)\n",
    "    else:\n",
    "        memory = DenseLayer(DenseLayer(features, QUERY_SIZE), QUERY_SIZE)\n",
    "        \n",
    "    to_decode = ConcatLayer([features, memory])\n",
    "    l_out = DenseLayer(to_decode, HIDDEN_SIZE)\n",
    "    l_out = DenseLayer(l_out, 1, nonlinearity=lasagne.nonlinearities.linear)\n",
    "    return l_out, memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAINING_SIZE = 100000\n",
    "DIGITS = 3\n",
    "\n",
    "QUERY_SIZE = 16\n",
    "MEMORY_SIZE = 64\n",
    "HIDDEN_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 100000\n"
     ]
    }
   ],
   "source": [
    "source_seqs, source_letters, source_letter_to_ix, target_seqs, target_letters, target_letter_to_ix =\\\n",
    "                    generate_data(TRAINING_SIZE, DIGITS, lambda a, b: a * b, '{}*{}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_out, memory = bazal_model(QUERY_SIZE, MEMORY_SIZE, HIDDEN_SIZE, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
