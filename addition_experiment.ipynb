{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addition experiment\n",
    "\n",
    "An implementation of sequence to sequence learning for performing addition\n",
    "\n",
    "* Input: \"535+61\"\n",
    "\n",
    "* Output: \"596\"\n",
    "\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "Input may optionally be inverted, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "Two digits inverted:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "Three digits inverted:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "Four digits inverted:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "Five digits inverted:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:\n",
      "b'C:\\\\Users\\\\tumanov\\\\AppData\\\\Local\\\\Temp\\\\try_flags_lv_rqodj.c:4:19: fatal error: cudnn.h: No such file or directory\\r\\ncompilation terminated.\\r\\n'\n",
      "Mapped name None to device cuda0: GeForce GTX 1070 (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_trainable(net):\n",
    "    for tags in net.params.values():\n",
    "        tags -= {'trainable', 'regularizable'}\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "INVERT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "HIDDEN_SIZE = 128\n",
    "LAYERS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(size, digits):\n",
    "    source_seqs = []\n",
    "    target_seqs = []\n",
    "    seen = set()\n",
    "    print('Generating data...')\n",
    "    while len(source_seqs) < TRAINING_SIZE:\n",
    "        f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                        for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "        a, b = f(), f()\n",
    "        # Skip any addition questions we've already seen\n",
    "        # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "        key = tuple(sorted((a, b)))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        # Pad the data with spaces such that it is always MAXLEN.\n",
    "        q = '{}+{}'.format(a, b)\n",
    "        ans = str(a + b)\n",
    "\n",
    "        source_seqs.append(q)\n",
    "        target_seqs.append([\"START\"] + list(ans) + [\"END\"])\n",
    "\n",
    "    print('Total addition questions:', len(source_seqs))\n",
    "    \n",
    "    target_letters = list(set([token for ts in target_seqs for token in ts]))\n",
    "    target_letter_to_ix = {ph:i for i,ph in enumerate(target_letters)}\n",
    "    \n",
    "    source_letters = list(set([token for word in source_seqs for token in word]))\n",
    "    source_letter_to_ix = {l:i for i,l in enumerate(source_letters)}\n",
    "    \n",
    "    return source_seqs, source_letters, source_letter_to_ix, \\\n",
    "           target_seqs, target_letters, target_letter_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n"
     ]
    }
   ],
   "source": [
    "source_seqs, source_letters, source_letter_to_ix, target_seqs, target_letters, target_letter_to_ix =\\\n",
    "                    generate_data(TRAINING_SIZE, DIGITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668+1 : 669\n",
      "45+570 : 615\n",
      "0+586 : 586\n",
      "3+44 : 47\n",
      "527+0 : 527\n"
     ]
    }
   ],
   "source": [
    "for source, target in zip(source_seqs[:5],target_seqs[:5]):\n",
    "    print( source,':',\"\".join(target[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_letters = list(set([token for word in source_seqs for token in word]))\n",
    "source_letter_to_ix = {l:i for i,l in enumerate(source_letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2921dd8a5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(list(map(len,target_seqs)),bins=25);\n",
    "\n",
    "# Truncate names longer than MAX_LEN characters. This can be changed\n",
    "MAX_LEN = min([150,max(list(map(len, target_seqs)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast everything from symbols into matrix of int32. Pad with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_matrix(sequences, token_to_i, max_len=None, PAX_ix=-1):\n",
    "    \"\"\"\n",
    "    Converts several sequences of tokens to a matrix, edible a neural network.\n",
    "    Crops at max_len(if given), pads shorter sequences with -1 or PAD_ix.\n",
    "    \"\"\"\n",
    "    max_len = max_len or max(map(len,sequences))\n",
    "    \n",
    "    matrix = np.zeros((len(sequences),max_len),dtype='int8') -1\n",
    "    for i,seq in enumerate(sequences):\n",
    "        \n",
    "        row_ix = [token_to_i.get(_, 0) for _ in seq[:max_len]]\n",
    "        matrix[i,:len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('token sequence', 'int32')\n",
    "output_sequence = T.matrix('target target_letters', 'int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##ENCODER\n",
    "l_in = InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "l_mask = InputLayer(shape=(None, None),input_var=T.neq(input_sequence,-1)) \n",
    "\n",
    "\n",
    "l_emb = non_trainable(EmbeddingLayer(l_in, len(source_letters),  len(source_letters), W=np.diag(np.ones(len(source_letters)))))\n",
    "l_rnn = LSTMLayer(l_emb, HIDDEN_SIZE, only_return_final=True, mask_input=l_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##DECODER\n",
    "dec_in = InputLayer(shape=(None, None),input_var=output_sequence)\n",
    "dec_mask = InputLayer(shape=(None, None),input_var=T.neq(output_sequence,-1))\n",
    "\n",
    "dec_emb = non_trainable(EmbeddingLayer(dec_in, len(target_letters), len(target_letters), W=np.diag(np.ones(len(target_letters)))))\n",
    "dec_rnn = LSTMLayer(dec_emb, num_units=HIDDEN_SIZE, cell_init=l_rnn, mask_input=dec_mask)\n",
    "# WARNING! if it's lstm use cell_init, not hid_init\n",
    "\n",
    "\n",
    "#flatten batch and time to be compatible with feedforward layers (will un-flatten later)\n",
    "dec_rnn_flat = reshape(dec_rnn, (-1,dec_rnn.output_shape[-1]))\n",
    "\n",
    "l_out = DenseLayer(dec_rnn_flat, len(target_letters), nonlinearity=lasagne.nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_model(nn):\n",
    "    # Model weights\n",
    "    weights = get_all_params(nn)\n",
    "    network_output = get_output(nn)\n",
    "    network_output = network_output.reshape([output_sequence.shape[0],\\\n",
    "                                         output_sequence.shape[1], -1])\n",
    "    predictions_flat = network_output[:,:-1,:].reshape([-1,len(target_letters)])\n",
    "    targets = output_sequence[:,1:].ravel()\n",
    "\n",
    "    #do not count loss for '-1' tokens\n",
    "    mask = T.nonzero(T.neq(targets,-1))\n",
    "\n",
    "    loss = lasagne.objectives.categorical_crossentropy(predictions_flat[mask], targets[mask]).mean()\n",
    "    updates = lasagne.updates.adam(loss,weights)\n",
    "    #training\n",
    "    train = theano.function([input_sequence, output_sequence], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "    #computing loss without training\n",
    "    compute_cost = theano.function([input_sequence, output_sequence], loss, allow_input_downcast=True)\n",
    "    #compile the function that computes probabilities for next token given previous text.\n",
    "\n",
    "    last_probas =network_output[:, -1]\n",
    "\n",
    "    probs = theano.function([input_sequence, output_sequence], last_probas)\n",
    "    return train, compute_cost, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, compute_cost, probs = handle_model(l_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation\n",
    "\n",
    "We now need to implement a function that generates output sequence given input.\n",
    "\n",
    "Such function must work thusly:\n",
    "```\n",
    "Init:\n",
    "x = input\n",
    "y = [\"START\"]\n",
    "\n",
    "While not_too_long:\n",
    "  p(y_next|x,y) = probabilities of next letter for y\n",
    "  \n",
    "  y_next ~ p(y_next|x,y)\n",
    "  \n",
    "  y.append(y_next)\n",
    "  \n",
    "  if y_next == \"END\":\n",
    "      break\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_output(input, probs, target_letters, target_letter_to_ix, source_letter_to_ix,\n",
    "                    output_prefix = (\"START\",),\n",
    "                    END_token=\"END\",\n",
    "                    temperature=1,\n",
    "                    sample=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implement a function that generates output sequence given input.\n",
    "    \n",
    "    We recommend (but not require) you to use the pseudo-code above and inline instructions.\n",
    "    \"\"\"\n",
    "    x = as_matrix([input], source_letter_to_ix) \n",
    "    output = list(output_prefix)\n",
    "    while True:\n",
    "        y = as_matrix([output], target_letter_to_ix)\n",
    "        next_y_probs = probs(x, y)\n",
    "        next_y_probs = (next_y_probs ** temperature) / (next_y_probs ** temperature).sum()\n",
    "        if sample:\n",
    "            next_y = np.random.choice(target_letters, p=next_y_probs[0])\n",
    "        else:\n",
    "            next_y = target_letters[next_y_probs[0].argmax()]\n",
    "        next_y = str(next_y)             \n",
    "        assert type(next_y) is str, \"please return token(string/character), not it's index\"\n",
    "        \n",
    "        output.append(next_y)\n",
    "\n",
    "        if next_y==END_token:\n",
    "            break\n",
    "            \n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_seqs = np.array(source_seqs)\n",
    "target_seqs = np.array(target_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_batch(source_seqs, source_letter_to_ix, target_seqs, target_letter_to_ix, batch_size):\n",
    "    \"\"\"samples a random batch of source and target sequences, batch_size elements\"\"\"\n",
    "    batch_ix = np.random.randint(0,len(source_seqs),size=batch_size)\n",
    "    source_seqs_batch=as_matrix(source_seqs[batch_ix], source_letter_to_ix) \n",
    "    target_seqs_batch=as_matrix(target_seqs[batch_ix], target_letter_to_ix)\n",
    "    \n",
    "    return source_seqs_batch,target_seqs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 average loss = 1.72235736110291\n",
      "0+677 : 156\n",
      "2+274 : 986\n",
      "38+285 : 496\n",
      "419+1 : 121\n",
      "578+4 : 703\n",
      "Epoch 1 average loss = 1.4547770704240068\n",
      "8+775 : 784\n",
      "956+804 : 1582\n",
      "314+59 : 356\n",
      "377+37 : 446\n",
      "335+168 : 442\n",
      "Epoch 2 average loss = 1.2557770901860552\n",
      "61+340 : 389\n",
      "13+412 : 435\n",
      "448+371 : 872\n",
      "283+475 : 797\n",
      "34+53 : 60\n",
      "Epoch 3 average loss = 1.121578669989569\n",
      "11+406 : 273\n",
      "696+87 : 866\n",
      "343+85 : 402\n",
      "100+909 : 1014\n",
      "528+29 : 545\n",
      "Epoch 4 average loss = 1.0221197427451496\n",
      "36+74 : 112\n",
      "35+18 : 47\n",
      "538+832 : 1370\n",
      "105+1 : 109\n",
      "742+31 : 762\n",
      "Epoch 5 average loss = 0.9404933533314098\n",
      "78+597 : 658\n",
      "9+891 : 898\n",
      "31+988 : 1017\n",
      "871+275 : 1151\n",
      "61+98 : 161\n",
      "Epoch 6 average loss = 0.8832813741927545\n",
      "199+31 : 223\n",
      "82+5 : 100\n",
      "347+765 : 1114\n",
      "18+612 : 628\n",
      "778+60 : 829\n",
      "Epoch 7 average loss = 0.8309315052543846\n",
      "601+58 : 656\n",
      "74+817 : 890\n",
      "219+54 : 239\n",
      "967+339 : 1244\n",
      "141+343 : 496\n",
      "Epoch 8 average loss = 0.7833198556252612\n",
      "959+91 : 1029\n",
      "48+148 : 197\n",
      "10+12 : 30\n",
      "536+382 : 915\n",
      "497+6 : 500\n",
      "Epoch 9 average loss = 0.7507693898674672\n",
      "45+74 : 118\n",
      "142+363 : 512\n",
      "401+282 : 801\n",
      "6+781 : 790\n",
      "7+598 : 599\n"
     ]
    }
   ],
   "source": [
    "#total N iterations\n",
    "n_epochs=10\n",
    "\n",
    "# how many minibatches are there in the epoch \n",
    "batches_per_epoch = 500\n",
    "\n",
    "#how many training sequences are processed in a single function call\n",
    "batch_size=64\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    try:\n",
    "\n",
    "        avg_cost = 0;\n",
    "\n",
    "        for _ in range(batches_per_epoch):\n",
    "\n",
    "            x,y = sample_batch(source_seqs, source_letter_to_ix, target_seqs, target_letter_to_ix, batch_size)\n",
    "            avg_cost += train(x, y).mean()\n",
    "\n",
    "        print(\"Epoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))\n",
    "        for i in range(5):\n",
    "            ind = np.random.randint(len(source_seqs))\n",
    "            print (source_seqs[ind],':', ''.join(generate_output(source_seqs[ind], probs, target_letters, target_letter_to_ix, \\\n",
    "                                                             source_letter_to_ix, sample=True)[1:-1]))\n",
    "\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bazal module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CerMemory(lasagne.layers.Layer):\n",
    "    def __init__(self, incoming, memory_size, M=lasagne.init.Orthogonal(), **kwargs):\n",
    "        super(CerMemory, self).__init__(incoming, **kwargs)\n",
    "        self.query_shape = self.input_shape[1]\n",
    "        self.memory_size = memory_size\n",
    "        self.M = self.add_param(M, (self.query_shape, memory_size), name='M')\n",
    "\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        m = self.M / T.sqrt(T.sqr(self.M).sum(axis=0)).reshape(self.M.shape[1], 1)\n",
    "        weights =  T.dot(input, m)\n",
    "        return T.dot(weights, m.T)\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.query_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvcNormalizer(lasagne.layers.Layer):\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        return (input.T / T.sqrt(T.sqr(input).sum(axis=1)).reshape(input.shape[0], 1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY_SIZE = 16\n",
    "MEMORY_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bazal_model(query_size, memory_size):\n",
    "\n",
    "    ##ENCODER\n",
    "    l_in = InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "    l_mask = InputLayer(shape=(None, None),input_var=T.neq(input_sequence,-1)) \n",
    "\n",
    "\n",
    "    l_emb = non_trainable(EmbeddingLayer(l_in, len(source_letters),  len(source_letters), W=np.diag(np.ones(len(source_letters)))))\n",
    "    features = LSTMLayer(l_emb, HIDDEN_SIZE, only_return_final=True, mask_input=l_mask)\n",
    "    ## QUERY BUILDER\n",
    "    query = DenseLayer(features, QUERY_SIZE, nonlinearity=None)\n",
    "    query = EvcNormalizer(query)\n",
    "    ## Memory\n",
    "    memory = CerMemory(query, MEMORY_SIZE)\n",
    "    \n",
    "    to_decode = ConcatLayer([features, memory])\n",
    "    \n",
    "    ##DECODER\n",
    "    dec_in = InputLayer(shape=(None, None),input_var=output_sequence)\n",
    "    dec_mask = InputLayer(shape=(None, None),input_var=T.neq(output_sequence,-1))\n",
    "\n",
    "    dec_emb = non_trainable(EmbeddingLayer(dec_in, len(target_letters), len(target_letters), W=np.diag(np.ones(len(target_letters)))))\n",
    "    dec_rnn = LSTMLayer(dec_emb, num_units=to_decode.output_shape[-1], cell_init=to_decode, mask_input=dec_mask)\n",
    "    # WARNING! if it's lstm use cell_init, not hid_init\n",
    "\n",
    "\n",
    "    #flatten batch and time to be compatible with feedforward layers (will un-flatten later)\n",
    "    dec_rnn_flat = reshape(dec_rnn, (-1,dec_rnn.output_shape[-1]))\n",
    "\n",
    "    l_out = DenseLayer(dec_rnn_flat, len(target_letters), nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return l_out, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_out, memory = bazal_model(QUERY_SIZE, MEMORY_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, compute_cost, probs = handle_model(l_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 average loss = 1.6863881913490928\n",
      "990+8 : 987\n",
      "215+1 : 22\n",
      "1+910 : 738\n",
      "5+897 : 518\n",
      "16+167 : 251\n",
      "Epoch 1 average loss = 1.347186820833203\n",
      "161+65 : 261\n",
      "125+25 : 27\n",
      "557+6 : 573\n",
      "110+25 : 132\n",
      "608+16 : 618\n",
      "Epoch 2 average loss = 1.1719685744079509\n",
      "549+246 : 778\n",
      "83+494 : 535\n",
      "281+373 : 666\n",
      "459+38 : 471\n",
      "301+625 : 970\n",
      "Epoch 3 average loss = 1.0526060302232518\n",
      "72+912 : 977\n",
      "20+414 : 441\n",
      "71+915 : 1002\n",
      "91+763 : 846\n",
      "522+23 : 556\n",
      "Epoch 4 average loss = 0.949715852765253\n",
      "253+93 : 357\n",
      "29+305 : 434\n",
      "774+916 : 1671\n",
      "51+319 : 361\n",
      "650+72 : 739\n",
      "Epoch 5 average loss = 0.8659991489751153\n",
      "4+119 : 219\n",
      "821+34 : 859\n",
      "693+74 : 769\n",
      "2+201 : 212\n",
      "561+741 : 1337\n",
      "Epoch 6 average loss = 0.7963561874314545\n",
      "55+54 : 116\n",
      "134+247 : 384\n",
      "21+992 : 1019\n",
      "6+811 : 813\n",
      "963+59 : 1025\n",
      "Epoch 7 average loss = 0.7303057232907519\n",
      "8+869 : 878\n",
      "27+358 : 392\n",
      "333+84 : 410\n",
      "437+857 : 1290\n",
      "462+4 : 471\n",
      "Epoch 8 average loss = 0.6707419930811301\n",
      "621+47 : 668\n",
      "588+277 : 857\n",
      "825+18 : 840\n",
      "53+549 : 598\n",
      "97+607 : 699\n",
      "Epoch 9 average loss = 0.6080882297174766\n",
      "98+87 : 178\n",
      "9+277 : 291\n",
      "9+594 : 595\n",
      "2+405 : 406\n",
      "407+480 : 903\n"
     ]
    }
   ],
   "source": [
    "#total N iterations\n",
    "n_epochs=10\n",
    "\n",
    "# how many minibatches are there in the epoch \n",
    "batches_per_epoch = 500\n",
    "\n",
    "#how many training sequences are processed in a single function call\n",
    "batch_size=64\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    try:\n",
    "\n",
    "        avg_cost = 0;\n",
    "\n",
    "        for _ in range(batches_per_epoch):\n",
    "\n",
    "            x,y = sample_batch(source_seqs, source_letter_to_ix, target_seqs, target_letter_to_ix, batch_size)\n",
    "            avg_cost += train(x, y).mean()\n",
    "\n",
    "        print(\"Epoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))\n",
    "        for i in range(5):\n",
    "            ind = np.random.randint(len(source_seqs))\n",
    "            print (source_seqs[ind],':', ''.join(generate_output(source_seqs[ind], probs, target_letters, target_letter_to_ix, \\\n",
    "                                                             source_letter_to_ix, sample=True)[1:-1]))\n",
    "\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M_add = np.array(memory.M.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same for prod problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
