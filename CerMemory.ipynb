{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def non_trainable(net):\n",
    "    for tags in net.params.values():\n",
    "        tags -= {'trainable', 'regularizable'}\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_matrix(sequences, token_to_i, max_len=None, PAX_ix=-1):\n",
    "    \"\"\"\n",
    "    Converts several sequences of tokens to a matrix, edible a neural network.\n",
    "    Crops at max_len(if given), pads shorter sequences with -1 or PAD_ix.\n",
    "    \"\"\"\n",
    "    max_len = max_len or max(map(len,sequences))\n",
    "    \n",
    "    matrix = np.zeros((len(sequences),max_len),dtype='int8') -1\n",
    "    for i,seq in enumerate(sequences):\n",
    "        \n",
    "        row_ix = [token_to_i.get(_, 0) for _ in seq[:max_len]]\n",
    "        matrix[i,:len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_batch(source_seqs, source_letter_to_ix, target_seqs, target_letter_to_ix, batch_size):\n",
    "    \"\"\"samples a random batch of source and target sequences, batch_size elements\"\"\"\n",
    "    batch_ix = np.random.randint(0,len(source_seqs),size=batch_size)\n",
    "    source_seqs_batch=as_matrix(source_seqs[batch_ix], source_letter_to_ix) \n",
    "    target_seqs_batch=as_matrix(target_seqs[batch_ix], target_letter_to_ix)\n",
    "    \n",
    "    return source_seqs_batch,target_seqs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_output(input, probs, target_letters, target_letter_to_ix, source_letter_to_ix,\n",
    "                    output_prefix = (\"START\",),\n",
    "                    END_token=\"END\",\n",
    "                    temperature=1,\n",
    "                    sample=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implement a function that generates output sequence given input.\n",
    "    \n",
    "    We recommend (but not require) you to use the pseudo-code above and inline instructions.\n",
    "    \"\"\"\n",
    "    x = as_matrix([input], source_letter_to_ix) \n",
    "    output = list(output_prefix)\n",
    "    while True:\n",
    "        y = as_matrix([output], target_letter_to_ix)\n",
    "        next_y_probs = probs(x, y)\n",
    "        next_y_probs = (next_y_probs ** temperature) / (next_y_probs ** temperature).sum()\n",
    "        if sample:\n",
    "            next_y = np.random.choice(target_letters, p=next_y_probs[0])\n",
    "        else:\n",
    "            next_y = target_letters[next_y_probs[0].argmax()]\n",
    "        next_y = str(next_y)             \n",
    "        assert type(next_y) is str, \"please return token(string/character), not it's index\"\n",
    "        \n",
    "        output.append(next_y)\n",
    "\n",
    "        if next_y==END_token:\n",
    "            break\n",
    "            \n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 200000\n",
    "DIGITS = 3\n",
    "INVERT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(size, digits, problem = lambda a, b: a*b, problem_operator='{}*{}'):\n",
    "    source_seqs = []\n",
    "    target_seqs = []\n",
    "    seen = set()\n",
    "    print('Generating data...')\n",
    "    while len(source_seqs) < TRAINING_SIZE:\n",
    "                    \n",
    "        f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                        for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "        a, b = f(), f()\n",
    "        # Skip any addition questions we've already seen\n",
    "        # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "        key = tuple(sorted((a, b)))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        # Pad the data with spaces such that it is always MAXLEN.\n",
    "        q = problem_operator.format(a, b)\n",
    "        ans = str(problem(a, b))\n",
    "\n",
    "        source_seqs.append(q)\n",
    "        target_seqs.append([\"START\"] + list(ans) + [\"END\"])\n",
    "\n",
    "    print('Total addition questions:', len(source_seqs))\n",
    "    \n",
    "    target_letters = list(set([token for ts in target_seqs for token in ts]))\n",
    "    target_letter_to_ix = {ph:i for i,ph in enumerate(target_letters)}\n",
    "    \n",
    "    source_letters = list(set([token for word in source_seqs for token in word]))\n",
    "    source_letter_to_ix = {l:i for i,l in enumerate(source_letters)}\n",
    "    \n",
    "    return np.array(source_seqs), source_letters, source_letter_to_ix, \\\n",
    "           np.array(target_seqs), target_letters, target_letter_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 200000\n"
     ]
    }
   ],
   "source": [
    "source_seqs, source_letters, source_letter_to_ix, target_seqs, target_letters, target_letter_to_ix =\\\n",
    "                    generate_data(TRAINING_SIZE, DIGITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842*51 : 42942\n",
      "44*2 : 88\n",
      "1*552 : 552\n",
      "929*41 : 38089\n",
      "91*445 : 40495\n"
     ]
    }
   ],
   "source": [
    "for source, target in zip(source_seqs[:5],target_seqs[:5]):\n",
    "    print( source,':',\"\".join(target[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29141ec7860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(list(map(len,target_seqs)),bins=25);\n",
    "\n",
    "# Truncate names longer than MAX_LEN characters. This can be changed\n",
    "MAX_LEN = min([150,max(list(map(len, target_seqs)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CerMemory(lasagne.layers.Layer):\n",
    "    def __init__(self, incoming, memory_shape, K=lasagne.init.Orthogonal(), V=lasagne.init.GlorotUniform(), **kwargs):\n",
    "        super(CerMemory, self).__init__(incoming, **kwargs)\n",
    "        self.query_shape = self.input_shape[1]\n",
    "        self.memory_size = memory_shape[0]\n",
    "        self.value_size = memory_shape[1]        \n",
    "        self.K = self.add_param(K, (self.query_shape, self.memory_size), name='K')\n",
    "        self.V = self.add_param(V, (self.memory_size, self.value_size), name='V')\n",
    "        print('Output shape: {}'.format( ('None', self.value_size)))\n",
    "        \n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        k = self.K / T.sqrt(T.sqr(self.K).sum(axis=0)).reshape(self.K.shape[1], 1)\n",
    "        weights =  T.dot(input, k)\n",
    "        return T.dot(weights, self.V)\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.value_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CerMemoryPD(lasagne.layers.Layer):\n",
    "    def __init__(self, incoming, memory_shape, V, K=lasagne.init.Orthogonal(), **kwargs):\n",
    "        super(CerMemoryPD, self).__init__(incoming, **kwargs)\n",
    "        self.query_shape = self.input_shape[1]\n",
    "        self.memory_size = memory_shape[0]\n",
    "        self.value_size = memory_shape[1]        \n",
    "        self.K = self.add_param(K, (self.query_shape, self.memory_size), name='K')\n",
    "        self.V = V\n",
    "        print('Output shape: {}'.format( ('None', self.value_size)))\n",
    "        \n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        k = self.K / T.sqrt(T.sqr(self.K).sum(axis=0)).reshape(self.K.shape[1], 1)\n",
    "        weights =  T.dot(input, k)\n",
    "        return T.dot(weights, self.V)\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.value_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EvcNormalizer(lasagne.layers.Layer):\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        return (input.T / T.sqrt(T.sqr(input).sum(axis=1)).reshape(input.shape[0], 1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('token sequence', 'int32')\n",
    "output_sequence = T.matrix('target target_letters', 'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bazal_model(query_size, memory_shape, hidden_size, V_init=None,\\\n",
    "                memory_benchmark=False, bidir_features=False, features_pass=False):\n",
    "\n",
    "    ##ENCODER\n",
    "    l_in = InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "    l_mask = InputLayer(shape=(None, None),input_var=T.neq(input_sequence,-1)) \n",
    "\n",
    "\n",
    "    l_emb = non_trainable(EmbeddingLayer(l_in, len(source_letters),  len(source_letters), W=np.diag(np.ones(len(source_letters)))))\n",
    "\n",
    "    features = LSTMLayer(l_emb, HIDDEN_SIZE, only_return_final=True, mask_input=l_mask)\n",
    "    features_backward = LSTMLayer(l_emb, HIDDEN_SIZE, only_return_final=True, mask_input=l_mask, backwards=True)\n",
    "    if bidir_features:\n",
    "        features = ConcatLayer([features, features_backward])\n",
    "    \n",
    "    if not memory_benchmark:\n",
    "        ## QUERY BUILDER\n",
    "        query = DenseLayer(features, QUERY_SIZE, nonlinearity=None)\n",
    "        query = EvcNormalizer(query)\n",
    "        ## Memory\n",
    "        if V_init is not None:\n",
    "            memory = CerMemoryPD(query, memory_shape, V_init)\n",
    "        else:\n",
    "            memory = CerMemory(query, memory_shape)\n",
    "    else:\n",
    "        memory = DenseLayer(DenseLayer(features, QUERY_SIZE), QUERY_SIZE)\n",
    "    \n",
    "    if features_pass:\n",
    "        to_decode = ConcatLayer([features, memory])\n",
    "    else:\n",
    "        to_decode = memory\n",
    "        \n",
    "    ##DECODER\n",
    "    dec_in = InputLayer(shape=(None, None),input_var=output_sequence)\n",
    "    dec_mask = InputLayer(shape=(None, None),input_var=T.neq(output_sequence,-1))\n",
    "\n",
    "    dec_emb = non_trainable(EmbeddingLayer(dec_in, len(target_letters), len(target_letters), W=np.diag(np.ones(len(target_letters)))))\n",
    "    dec_rnn = LSTMLayer(dec_emb, num_units=to_decode.output_shape[-1], cell_init=to_decode, mask_input=dec_mask)\n",
    "    # WARNING! if it's lstm use cell_init, not hid_init\n",
    "\n",
    "\n",
    "    #flatten batch and time to be compatible with feedforward layers (will un-flatten later)\n",
    "    dec_rnn_flat = reshape(dec_rnn, (-1,dec_rnn.output_shape[-1]))\n",
    "\n",
    "    l_out = DenseLayer(dec_rnn_flat, len(target_letters), nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return l_out, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_model(nn, learning_rate_init=0.001):\n",
    "    # Model weights\n",
    "    \n",
    "    weights = get_all_params(nn)\n",
    "    network_output = get_output(nn)\n",
    "    network_output = network_output.reshape([output_sequence.shape[0],\\\n",
    "                                         output_sequence.shape[1], -1])\n",
    "    predictions_flat = network_output[:,:-1,:].reshape([-1,len(target_letters)])\n",
    "    targets = output_sequence[:,1:].ravel()\n",
    "\n",
    "    #do not count loss for '-1' tokens\n",
    "    mask = T.nonzero(T.neq(targets,-1))\n",
    "\n",
    "    loss = lasagne.objectives.categorical_crossentropy(predictions_flat[mask], targets[mask]).mean()\n",
    "    lr = theano.shared(learning_rate_init)\n",
    "    updates = lasagne.updates.adam(loss, weights, learning_rate=lr)\n",
    "    #training\n",
    "    train = theano.function([input_sequence, output_sequence], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "    #computing loss without training\n",
    "    compute_cost = theano.function([input_sequence, output_sequence], loss, allow_input_downcast=True)\n",
    "    #compile the function that computes probabilities for next token given previous text.\n",
    "\n",
    "    last_probas =network_output[:, -1]\n",
    "\n",
    "    probs = theano.function([input_sequence, output_sequence], last_probas)\n",
    "    return train, compute_cost, probs, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY_SIZE = 64\n",
    "MEMORY_SHAPE = (128, 64)\n",
    "HIDDEN_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#V_init = np.zeros((1000, 1000))\n",
    "#for i in range(1000):\n",
    "#    for j in range(1000):\n",
    "#        V_init[i, j] = float(i*j) / 10 ** 6\n",
    "#V_init = V_init.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: ('None', 1)\n"
     ]
    }
   ],
   "source": [
    "l_out, memory = bazal_model(QUERY_SIZE, MEMORY_SHAPE, HIDDEN_SIZE, V_init=None, features_pass=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, compute_cost, probs, lr = handle_model(l_out, learning_rate_init=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 80/100 [00:00<00:00, 797.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 807.53it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(100)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:14<00:00,  3.70it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train average loss = 2.4239304325387767\n",
      "Epoch 0 val average loss = 2.325664573193485\n",
      "311*85 : 85660  |  26435\n",
      "59*514 : 24909370  |  30326\n",
      "705*680 : START5491  |  479400\n",
      "377*260 : 926  |  98020\n",
      "154*174 : 85START2233  |  26796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:15<00:00,  3.69it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train average loss = 2.244496118182059\n",
      "Epoch 1 val average loss = 2.1894528490856753\n",
      "803*221 : 69063  |  177463\n",
      "300*269 : 150  |  80700\n",
      "327*44 : 28START66  |  14388\n",
      "373*134 :   |  49982\n",
      "80*136 : 0109  |  10880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:15<00:00,  3.69it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train average loss = 2.164008677629182\n",
      "Epoch 2 val average loss = 2.1413430983393105\n",
      "764*867 : 301266START6  |  662388\n",
      "909*58 : 84766  |  52722\n",
      "157*11 : 556189  |  1727\n",
      "243*467 : 16502  |  113481\n",
      "78*667 : 280START32START440  |  52026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:15<00:00,  3.69it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train average loss = 2.1296916094615232\n",
      "Epoch 3 val average loss = 2.116152510842336\n",
      "849*120 : 6990  |  101880\n",
      "543*792 : 68339  |  430056\n",
      "39*5 : 5569  |  195\n",
      "171*896 : 01941  |  153216\n",
      "642*44 : 2521  |  28248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:09<00:00,  3.86it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train average loss = 2.1118805470238713\n",
      "Epoch 4 val average loss = 2.1015754177294523\n",
      "727*450 : 45285  |  327150\n",
      "539*306 : 0881  |  164934\n",
      "479*71 : 612364  |  34009\n",
      "976*551 : 34115  |  537776\n",
      "49*738 : 15START614  |  36162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:15<00:00,  3.69it/s]\n",
      "100%|██████████| 50/50 [00:03<00:00, 14.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train average loss = 2.0996960975179064\n",
      "Epoch 5 val average loss = 2.0939266796471285\n",
      "771*21 : 850044  |  16191\n",
      "49*719 : 93887  |  35231\n",
      "44*49 : 60  |  2156\n",
      "281*482 : 8339  |  135442\n",
      "841*39 : 3227680  |  32799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 61/500 [00:16<01:59,  3.69it/s]"
     ]
    }
   ],
   "source": [
    "#total N iterations\n",
    "n_epochs=300\n",
    "\n",
    "# how many minibatches are there in the epoch \n",
    "train_batches_per_epoch = 500\n",
    "val_batches_per_epoch = 50\n",
    "\n",
    "#how many training sequences are processed in a single function call\n",
    "batch_size=64\n",
    "\n",
    "\n",
    "train_source_seqs, val_source_seqs, train_target_seqs, val_target_seqs = train_test_split(source_seqs, target_seqs,\\\n",
    "                                                                                          test_size=0.15, random_state=42)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    try:\n",
    "\n",
    "        train_avg_cost = 0;\n",
    "        val_avg_cost = 0;\n",
    "        if epoch != 0 and epoch % 30==0:\n",
    "            lr.set_value(lr.get_value() / 10.)\n",
    "        \n",
    "        for _ in tqdm.tqdm(range(train_batches_per_epoch)):\n",
    "            x,y = sample_batch(train_source_seqs, source_letter_to_ix, train_target_seqs, target_letter_to_ix, batch_size)\n",
    "            train_avg_cost += train(x, y).mean()\n",
    "        \n",
    "        for _ in tqdm.tqdm(range(val_batches_per_epoch)):\n",
    "            x,y = sample_batch(val_source_seqs, source_letter_to_ix, val_target_seqs, target_letter_to_ix, batch_size)\n",
    "            val_avg_cost += compute_cost(x, y).mean()\n",
    "\n",
    "        print(\"Epoch {} train average loss = {}\".format(epoch, train_avg_cost / train_batches_per_epoch))\n",
    "        print(\"Epoch {} val average loss = {}\".format(epoch, val_avg_cost / val_batches_per_epoch))\n",
    "        \n",
    "        for i in range(5):\n",
    "            ind = np.random.randint(len(val_source_seqs))\n",
    "            print (val_source_seqs[ind],':', ''.join(generate_output(val_source_seqs[ind], probs, target_letters, target_letter_to_ix, \\\n",
    "                                                             source_letter_to_ix, sample=True)[1:-1]),' | ', ''.join(val_target_seqs[ind][1:-1]))\n",
    "\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#K_prod = np.array(memory.K.eval())\n",
    "#V_prod = np.array(memory.V.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.save('./zoo/prod_memory_K_afterINFepochs.npy', K_prod)\n",
    "#np.save('./zoo/prod_memory_V_afterINFepochs.npy', V_prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
