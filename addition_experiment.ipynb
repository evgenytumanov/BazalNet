{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addition experiment\n",
    "\n",
    "An implementation of sequence to sequence learning for performing addition\n",
    "\n",
    "* Input: \"535+61\"\n",
    "\n",
    "* Output: \"596\"\n",
    "\n",
    "Padding is handled by using a repeated sentinel character (space)\n",
    "Input may optionally be inverted, shown to increase performance in many tasks in:\n",
    "\"Learning to Execute\"\n",
    "http://arxiv.org/abs/1410.4615\n",
    "and\n",
    "\"Sequence to Sequence Learning with Neural Networks\"\n",
    "http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf\n",
    "Theoretically it introduces shorter term dependencies between source and target.\n",
    "Two digits inverted:\n",
    "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
    "Three digits inverted:\n",
    "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
    "Four digits inverted:\n",
    "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
    "Five digits inverted:\n",
    "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "INVERT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try replacing GRU, or SimpleRNN.\n",
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 128\n",
    "LAYERS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "('Total addition questions:', 50000)\n"
     ]
    }
   ],
   "source": [
    "source_seqs = []\n",
    "target_seqs = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(source_seqs) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    ans = str(a + b)\n",
    "    \n",
    "    source_seqs.append(q)\n",
    "    target_seqs.append([\"START\"] + list(ans) + [\"END\"])\n",
    "    \n",
    "print('Total addition questions:', len(source_seqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('4+953', ':', '957')\n",
      "('610+6', ':', '616')\n",
      "('8+8', ':', '16')\n",
      "('51+4', ':', '55')\n",
      "('823+4', ':', '827')\n"
     ]
    }
   ],
   "source": [
    "for source, target in zip(source_seqs[:5],target_seqs[:5]):\n",
    "    print( source,':',\"\".join(target[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_letters = list(set([token for ts in target_seqs for token in ts]))\n",
    "target_letter_to_ix = {ph:i for i,ph in enumerate(target_letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_letters = list(set([token for word in source_seqs for token in word]))\n",
    "source_letter_to_ix = {l:i for i,l in enumerate(source_letters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa56f7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(list(map(len,target_seqs)),bins=25);\n",
    "\n",
    "# Truncate names longer than MAX_LEN characters. This can be changed\n",
    "MAX_LEN = min([150,max(list(map(len, target_seqs)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cast everything from symbols into matrix of int32. Pad with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_matrix(sequences, token_to_i, max_len=None, PAX_ix=-1):\n",
    "    \"\"\"\n",
    "    Converts several sequences of tokens to a matrix, edible a neural network.\n",
    "    Crops at max_len(if given), pads shorter sequences with -1 or PAD_ix.\n",
    "    \"\"\"\n",
    "    max_len = max_len or max(map(len,sequences))\n",
    "    \n",
    "    matrix = np.zeros((len(sequences),max_len),dtype='int8') -1\n",
    "    for i,seq in enumerate(sequences):\n",
    "        \n",
    "        row_ix = [token_to_i.get(_, 0) for _ in seq[:max_len]]\n",
    "        matrix[i,:len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('token sequence', 'int32')\n",
    "output_sequence = T.matrix('target target_letters', 'int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_trainable(net):\n",
    "    for tags in net.params.itervalues():\n",
    "        tags -= {'trainable', 'regularizable'}\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##ENCODER\n",
    "l_in = InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "l_mask = InputLayer(shape=(None, None),input_var=T.neq(input_sequence,-1)) \n",
    "\n",
    "\n",
    "l_emb = non_trainable(EmbeddingLayer(l_in, len(source_letters),  len(source_letters), W=np.diag(np.ones(len(source_letters)))))\n",
    "l_rnn = LSTMLayer(l_emb, HIDDEN_SIZE, only_return_final=True, mask_input=l_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DECODER\n",
    "dec_in = InputLayer(shape=(None, None),input_var=output_sequence)\n",
    "dec_mask = InputLayer(shape=(None, None),input_var=T.neq(output_sequence,-1))\n",
    "\n",
    "dec_emb = non_trainable(EmbeddingLayer(dec_in, len(target_letters), len(target_letters), W=np.diag(np.ones(len(target_letters)))))\n",
    "dec_rnn = LSTMLayer(dec_emb, num_units=HIDDEN_SIZE, cell_init=l_rnn, mask_input=dec_mask)\n",
    "# WARNING! if it's lstm use cell_init, not hid_init\n",
    "\n",
    "\n",
    "#flatten batch and time to be compatible with feedforward layers (will un-flatten later)\n",
    "dec_rnn_flat = reshape(dec_rnn, (-1,dec_rnn.output_shape[-1]))\n",
    "\n",
    "l_out = DenseLayer(dec_rnn_flat, len(target_letters), nonlinearity=lasagne.nonlinearities.softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model weights\n",
    "weights = get_all_params(l_out)\n",
    "#print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_output = get_output(l_out)\n",
    "network_output = network_output.reshape([output_sequence.shape[0],\\\n",
    "                                         output_sequence.shape[1], -1])\n",
    "#If you use dropout do not forget to create deterministic version for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_flat = network_output[:,:-1,:].reshape([-1,len(target_letters)])\n",
    "targets = output_sequence[:,1:].ravel()\n",
    "\n",
    "#do not count loss for '-1' tokens\n",
    "mask = T.nonzero(T.neq(targets,-1))\n",
    "\n",
    "loss = lasagne.objectives.categorical_crossentropy(predictions_flat[mask], targets[mask]).mean()\n",
    "updates = lasagne.updates.adam(loss,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "train = theano.function([input_sequence, output_sequence], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "#computing loss without training\n",
    "compute_cost = theano.function([input_sequence, output_sequence], loss, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation\n",
    "\n",
    "We now need to implement a function that generates output sequence given input.\n",
    "\n",
    "Such function must work thusly:\n",
    "```\n",
    "Init:\n",
    "x = input\n",
    "y = [\"START\"]\n",
    "\n",
    "While not_too_long:\n",
    "  p(y_next|x,y) = probabilities of next letter for y\n",
    "  \n",
    "  y_next ~ p(y_next|x,y)\n",
    "  \n",
    "  y.append(y_next)\n",
    "  \n",
    "  if y_next == \"END\":\n",
    "      break\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compile the function that computes probabilities for next token given previous text.\n",
    "\n",
    "last_probas =network_output[:, -1]\n",
    "\n",
    "probs = theano.function([input_sequence, output_sequence], last_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_output(input,\n",
    "                    output_prefix = (\"START\",),\n",
    "                    END_token=\"END\",\n",
    "                    temperature=1,\n",
    "                    sample=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implement a function that generates output sequence given input.\n",
    "    \n",
    "    We recommend (but not require) you to use the pseudo-code above and inline instructions.\n",
    "    \"\"\"\n",
    "    x = as_matrix([input], source_letter_to_ix) \n",
    "    output = list(output_prefix)\n",
    "    while True:\n",
    "        y = as_matrix([output], target_letter_to_ix)\n",
    "        next_y_probs = probs(x, y)\n",
    "        next_y_probs = (next_y_probs ** temperature) / (next_y_probs ** temperature).sum()\n",
    "        if sample:\n",
    "            next_y = np.random.choice(target_letters, p=next_y_probs[0])\n",
    "        else:\n",
    "            next_y = target_letters[next_y_probs[0].argmax()]\n",
    "        next_y = str(next_y)             \n",
    "        assert type(next_y) is str, \"please return token(string/character), not it's index\"\n",
    "        \n",
    "        output.append(next_y)\n",
    "\n",
    "        if next_y==END_token:\n",
    "            break\n",
    "            \n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_seqs = np.array(source_seqs)\n",
    "target_seqs = np.array(target_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_batch(source_seqs,target_seqs, batch_size):\n",
    "    \"\"\"samples a random batch of source and target sequences, batch_size elements\"\"\"\n",
    "    batch_ix = np.random.randint(0,len(source_seqs),size=batch_size)\n",
    "    source_seqs_batch=as_matrix(source_seqs[batch_ix], source_letter_to_ix) \n",
    "    target_seqs_batch=as_matrix(target_seqs[batch_ix], target_letter_to_ix)\n",
    "    \n",
    "    return source_seqs_batch,target_seqs_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 average loss = 1.69220353855\n",
      "('248+84', ':', '316')\n",
      "('62+256', ':', '413')\n",
      "('7+126', ':', '118')\n",
      "('155+1', ':', '259')\n",
      "('976+62', ':', '1165')\n",
      "Epoch 1 average loss = 1.33267121568\n",
      "('7+404', ':', '611')\n",
      "('440+24', ':', '429')\n",
      "('74+827', ':', '907')\n",
      "('768+70', ':', '904')\n",
      "('590+637', ':', '1333')\n",
      "Epoch 2 average loss = 1.13213952782\n",
      "('846+363', ':', '1157')\n",
      "('43+693', ':', '734')\n",
      "('9+288', ':', '289')\n",
      "('278+49', ':', '310')\n",
      "('927+416', ':', '1326')\n",
      "Epoch 3 average loss = 0.993167940189\n",
      "('658+37', ':', '690')\n",
      "('743+3', ':', '738')\n",
      "('286+628', ':', '964')\n",
      "('60+424', ':', '489')\n",
      "('498+3', ':', '501')\n",
      "Epoch 4 average loss = 0.895050642466\n",
      "('738+19', ':', '752')\n",
      "('568+4', ':', '663')\n",
      "('614+209', ':', '855')\n",
      "('99+623', ':', '719')\n",
      "('30+528', ':', '558')\n",
      "Epoch 5 average loss = 0.819492927735\n",
      "('542+962', ':', '1466')\n",
      "('946+55', ':', '989')\n",
      "('1+136', ':', '143')\n",
      "('644+56', ':', '702')\n",
      "('441+569', ':', '1011')\n",
      "Epoch 6 average loss = 0.761436612451\n",
      "('72+968', ':', '1037')\n",
      "('109+855', ':', '975')\n",
      "('55+537', ':', '590')\n",
      "('950+490', ':', '1412')\n",
      "('653+6', ':', '659')\n",
      "Epoch 7 average loss = 0.705848570603\n",
      "('163+282', ':', '450')\n",
      "('73+948', ':', '1020')\n",
      "('18+364', ':', '368')\n",
      "('45+22', ':', '80')\n",
      "('898+17', ':', '906')\n",
      "Epoch 8 average loss = 0.665949550302\n",
      "('549+79', ':', '627')\n",
      "('18+669', ':', '679')\n",
      "('41+80', ':', '124')\n",
      "('33+666', ':', '700')\n",
      "('24+685', ':', '712')\n",
      "Epoch 9 average loss = 0.624299508397\n",
      "('429+530', ':', '961')\n",
      "('687+938', ':', '1610')\n",
      "('96+670', ':', '768')\n",
      "('27+978', ':', '1011')\n",
      "('46+539', ':', '601')\n",
      "Epoch 10 average loss = 0.58715149809\n",
      "('937+11', ':', '944')\n",
      "('458+617', ':', '1069')\n",
      "('288+812', ':', '1110')\n",
      "('403+66', ':', '469')\n",
      "('782+613', ':', '1402')\n",
      "Epoch 11 average loss = 0.552232785131\n",
      "('25+263', ':', '288')\n",
      "('908+49', ':', '957')\n",
      "('958+3', ':', '965')\n",
      "('12+514', ':', '527')\n",
      "('7+830', ':', '840')\n",
      "Epoch 12 average loss = 0.504467398548\n",
      "('95+515', ':', '609')\n",
      "('762+1', ':', '762')\n",
      "('8+517', ':', '532')\n",
      "('108+735', ':', '754')\n",
      "('256+17', ':', '281')\n"
     ]
    }
   ],
   "source": [
    "#total N iterations\n",
    "n_epochs=100\n",
    "\n",
    "# how many minibatches are there in the epoch \n",
    "batches_per_epoch = 500\n",
    "\n",
    "#how many training sequences are processed in a single function call\n",
    "batch_size=BATCH_SIZE\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "\n",
    "    avg_cost = 0;\n",
    "    \n",
    "    for _ in range(batches_per_epoch):\n",
    "        \n",
    "        x,y = sample_batch(source_seqs,target_seqs,batch_size)\n",
    "        avg_cost += train(x, y).mean()\n",
    "        \n",
    "    print(\"Epoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))\n",
    "    for i in range(5):\n",
    "        ind = np.random.randint(len(source_seqs))\n",
    "        print (source_seqs[ind],':', ''.join(generate_output(source_seqs[ind],sample=True)[1:-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
