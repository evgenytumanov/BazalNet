{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD:CerMemory.ipynb
      "DEBUG: nvcc STDOUT nvcc warning : The 'compute_20', 'sm_20', and 'sm_21' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "mod.cu\n",
      "   Creating library C:/Users/etumanov/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.13-64/tmpc0cz2g/265abc51f7c376c224983485238ff1a5.lib and object C:/Users/etumanov/AppData/Local/Theano/compiledir_Windows-10-10.0.14393-Intel64_Family_6_Model_63_Stepping_2_GenuineIntel-2.7.13-64/tmpc0cz2g/265abc51f7c376c224983485238ff1a5.exp\n",
      "\n",
      "Using gpu device 0: GeForce GTX 780 (CNMeM is disabled, cuDNN 5005)\n"
=======
<<<<<<< HEAD:notebooks/CerMemory.ipynb
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "Can not use cuDNN on context None: cannot compile with cuDNN. We got this error:\n",
      "b'C:\\\\Users\\\\tumanov\\\\AppData\\\\Local\\\\Temp\\\\try_flags_kbnzoj6a.c:4:19: fatal error: cudnn.h: No such file or directory\\r\\ncompilation terminated.\\r\\n'\n",
      "Mapped name None to device cuda0: GeForce GTX 1070 (0000:01:00.0)\n"
=======
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
>>>>>>> 709000a4bf40ec55cefec24a29613c5834b9e450:CerMemory.ipynb
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GpuElemwise{exp,no_inplace}(<CudaNdarrayType(float32, vector)>), HostFromGpu(GpuElemwise{exp,no_inplace}.0)]\n",
      "Looping 1000 times took 0.849000 seconds\n",
      "Result is [1.2317803 1.6187935 1.5227807 ... 2.2077181 2.2996776 1.623233 ]\n",
      "Used the gpu\n"
     ]
    }
   ],
   "source": [
    "from theano import function, config, shared, tensor\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], tensor.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, tensor.Elemwise) and\n",
    "              ('Gpu' not in type(x.op).__name__)\n",
    "              for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 4,
=======
   "execution_count": 2,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def non_trainable(net):\n",
    "    for tags in net.params.values():\n",
    "        tags -= {'trainable', 'regularizable'}\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 5,
=======
   "execution_count": 3,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def as_matrix(sequences, token_to_i, max_len=None, PAX_ix=-1):\n",
    "    \"\"\"\n",
    "    Converts several sequences of tokens to a matrix, edible a neural network.\n",
    "    Crops at max_len(if given), pads shorter sequences with -1 or PAD_ix.\n",
    "    \"\"\"\n",
    "    max_len = max_len or max(map(len,sequences))\n",
    "    \n",
    "    matrix = np.zeros((len(sequences),max_len),dtype='int8') -1\n",
    "    for i,seq in enumerate(sequences):\n",
    "        \n",
    "        row_ix = [token_to_i.get(_, 0) for _ in seq[:max_len]]\n",
    "        matrix[i,:len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 6,
=======
   "execution_count": 4,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_batch(source_seqs, source_letter_to_ix, target_seqs, target_letter_to_ix, batch_size):\n",
    "    \"\"\"samples a random batch of source and target sequences, batch_size elements\"\"\"\n",
    "    batch_ix = np.random.randint(0,len(source_seqs),size=batch_size)\n",
    "    source_seqs_batch=as_matrix(source_seqs[batch_ix], source_letter_to_ix) \n",
    "    target_seqs_batch=as_matrix(target_seqs[batch_ix], target_letter_to_ix)\n",
    "    \n",
    "    return source_seqs_batch,target_seqs_batch"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 7,
=======
   "execution_count": 5,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_output(input, probs, target_letters, target_letter_to_ix, source_letter_to_ix,\n",
    "                    output_prefix = (\"START\",),\n",
    "                    END_token=\"END\",\n",
    "                    temperature=1,\n",
    "                    sample=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implement a function that generates output sequence given input.\n",
    "    \n",
    "    We recommend (but not require) you to use the pseudo-code above and inline instructions.\n",
    "    \"\"\"\n",
    "    x = as_matrix([input], source_letter_to_ix) \n",
    "    output = list(output_prefix)\n",
    "    while True:\n",
    "        y = as_matrix([output], target_letter_to_ix)\n",
    "        next_y_probs = probs(x, y)\n",
    "        next_y_probs = (next_y_probs ** temperature) / (next_y_probs ** temperature).sum()\n",
    "        if sample:\n",
    "            next_y = np.random.choice(target_letters, p=next_y_probs[0])\n",
    "        else:\n",
    "            next_y = target_letters[next_y_probs[0].argmax()]\n",
    "        next_y = str(next_y)             \n",
    "        assert type(next_y) is str, \"please return token(string/character), not it's index\"\n",
    "        \n",
    "        output.append(next_y)\n",
    "\n",
    "        if next_y==END_token:\n",
    "            break\n",
    "            \n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 8,
=======
   "execution_count": 6,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 500000\n",
    "DIGITS = 5\n",
    "INVERT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 9,
=======
   "execution_count": 7,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(size, digits, problem = lambda a, b: a*b, problem_operator='{}*{}'):\n",
    "    source_seqs = []\n",
    "    target_seqs = []\n",
    "    seen = set()\n",
    "    print('Generating data...')\n",
    "    while len(source_seqs) < TRAINING_SIZE:\n",
    "                    \n",
    "        f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                        for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "        a, b = f(), f()\n",
    "        # Skip any addition questions we've already seen\n",
    "        # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "        key = tuple(sorted((a, b)))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        # Pad the data with spaces such that it is always MAXLEN.\n",
    "        q = problem_operator.format(a, b)\n",
    "        ans = str(problem(a, b))\n",
    "\n",
    "        source_seqs.append(q)\n",
    "        target_seqs.append([\"START\"] + list(ans) + [\"END\"])\n",
    "\n",
    "    print('Total addition questions:', len(source_seqs))\n",
    "    \n",
    "    target_letters = list(set([token for ts in target_seqs for token in ts]))\n",
    "    target_letter_to_ix = {ph:i for i,ph in enumerate(target_letters)}\n",
    "    \n",
    "    source_letters = list(set([token for word in source_seqs for token in word]))\n",
    "    source_letter_to_ix = {l:i for i,l in enumerate(source_letters)}\n",
    "    \n",
    "    return np.array(source_seqs), source_letters, source_letter_to_ix, \\\n",
    "           np.array(target_seqs), target_letters, target_letter_to_ix"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 10,
=======
   "execution_count": 8,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
<<<<<<< HEAD:CerMemory.ipynb
      "('Total addition questions:', 200000)\n"
=======
      "Total addition questions: 500000\n"
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
     ]
    }
   ],
   "source": [
    "source_seqs, source_letters, source_letter_to_ix, target_seqs, target_letters, target_letter_to_ix =\\\n",
    "                    generate_data(TRAINING_SIZE, DIGITS)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 11,
=======
   "execution_count": 9,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD:CerMemory.ipynb
      "('48*763', ':', '36624')\n",
      "('130*503', ':', '65390')\n",
      "('16*818', ':', '13088')\n",
      "('0*46', ':', '0')\n",
      "('46*8', ':', '368')\n"
=======
      "78423*78416 : 6149617968\n",
      "20528*69614 : 1429036192\n",
      "7*0 : 0\n",
      "459*4 : 1836\n",
      "61920*0 : 0\n"
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
     ]
    }
   ],
   "source": [
    "for source, target in zip(source_seqs[:5],target_seqs[:5]):\n",
    "    print( source,':',\"\".join(target[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 12,
=======
   "execution_count": 10,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD:CerMemory.ipynb
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLGUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21d7d4e0>"
=======
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAE8tJREFUeJzt3WGoXWV+7/Hv7yat40zRiRqCTeQmYJiioWVqcGwHynBT\nxtzrMPGFSoZOTdtUKdp2Wi4MSftCaAkoLddWqEIYrdGKGtIphlo7E+Itw32ROMexVKNjPYw6Jo3m\n1Fi9tOg09t8X+zmdnTOJeTz75OwT8/3AZq/9X+tZ+78XhF+etdbeJ1WFJEk9/tu4G5AknTkMDUlS\nN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3RaPu4G5dtFFF9XKlSvH3YYknVGefvrp\nf66qpafa7iMXGitXrmRiYmLcbUjSGSXJqz3beXpKktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUz\nNCRJ3QwNSVI3Q0OS1O0j941w6Uy0csvjH2r7V26/5jR1In0wZxqSpG6GhiSpm6EhSep2ytBIcl+S\nI0meG6r9UZLvJvmHJH+V5JND67YmmUzyYpKrh+pXJHm2rbsrSVr9nCSPtvr+JCuHxmxK8lJ7bJqr\nDy1Jmp2emcb9wPoZtT3Amqr6aeAfga0ASS4DNgKXtzF3J1nUxtwD3ASsbo/pfW4G3qqqS4E7gTva\nvi4AbgM+A1wJ3JZkyYf/iJKkuXLK0KiqbwFHZ9S+WVXH2st9wIq2vAF4pKreq6qXgUngyiQXA+dV\n1b6qKuAB4NqhMTva8i5gXZuFXA3sqaqjVfUWg6CaGV6SpHk0F9c0fg14oi0vB14bWnew1Za35Zn1\n48a0IHobuPAD9vUjktycZCLJxNTU1EgfRpJ0ciOFRpLfB44BD81NO7NTVduram1VrV269JR/rVCS\nNEuzDo0kvwJ8AfildsoJ4BBwydBmK1rtED88hTVcP25MksXA+cCbH7AvSdKYzCo0kqwHvgp8sar+\nbWjVbmBjuyNqFYML3k9V1WHgnSRXtesVNwKPDY2ZvjPqOuDJFkLfAD6fZEm7AP75VpMkjckpf0Yk\nycPA54CLkhxkcEfTVuAcYE+7c3ZfVf1GVR1IshN4nsFpq1ur6v22q1sY3Il1LoNrINPXQe4FHkwy\nyeCC+0aAqjqa5A+Bb7ft/qCqjrsgL0maX6cMjar60gnK937A9tuAbSeoTwBrTlB/F7j+JPu6D7jv\nVD1KkuaH3wiXJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1J\nUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1J\nUrfF425A0sKzcsvjH3rMK7dfcxo60UJzyplGkvuSHEny3FDtgiR7krzUnpcMrduaZDLJi0muHqpf\nkeTZtu6uJGn1c5I82ur7k6wcGrOpvcdLSTbN1YeWJM1Oz+mp+4H1M2pbgL1VtRrY216T5DJgI3B5\nG3N3kkVtzD3ATcDq9pje52bgraq6FLgTuKPt6wLgNuAzwJXAbcPhJEmaf6cMjar6FnB0RnkDsKMt\n7wCuHao/UlXvVdXLwCRwZZKLgfOqal9VFfDAjDHT+9oFrGuzkKuBPVV1tKreAvbwo+ElSZpHs70Q\nvqyqDrfl14FlbXk58NrQdgdbbXlbnlk/bkxVHQPeBi78gH1JksZk5Lun2syh5qCXWUtyc5KJJBNT\nU1PjbEWSPtJmGxpvtFNOtOcjrX4IuGRouxWtdqgtz6wfNybJYuB84M0P2NePqKrtVbW2qtYuXbp0\nlh9JknQqsw2N3cD03UybgMeG6hvbHVGrGFzwfqqdynonyVXtesWNM8ZM7+s64Mk2e/kG8PkkS9oF\n8M+3miRpTE75PY0kDwOfAy5KcpDBHU23AzuTbAZeBW4AqKoDSXYCzwPHgFur6v22q1sY3Il1LvBE\newDcCzyYZJLBBfeNbV9Hk/wh8O223R9U1cwL8pKkeXTK0KiqL51k1bqTbL8N2HaC+gSw5gT1d4Hr\nT7Kv+4D7TtWjJGl++DMikqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG7+\nuVepw4f986f+6VN9VDnTkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUz\nNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd1GCo0kv5vkQJLnkjyc5GNJLkiyJ8lL7XnJ0PZbk0wmeTHJ\n1UP1K5I829bdlSStfk6SR1t9f5KVo/QrSRrNrEMjyXLgt4G1VbUGWARsBLYAe6tqNbC3vSbJZW39\n5cB64O4ki9ru7gFuAla3x/pW3wy8VVWXAncCd8y2X0nS6EY9PbUYODfJYuDjwD8BG4Adbf0O4Nq2\nvAF4pKreq6qXgUngyiQXA+dV1b6qKuCBGWOm97ULWDc9C5Ekzb9Zh0ZVHQL+GPg+cBh4u6q+CSyr\nqsNts9eBZW15OfDa0C4OttrytjyzftyYqjoGvA1cONueJUmjGeX01BIGM4FVwE8Cn0jy5eFt2syh\nRuqwr5ebk0wkmZiamjrdbydJZ61RTk/9IvByVU1V1b8DXwd+HnijnXKiPR9p2x8CLhkav6LVDrXl\nmfXjxrRTYOcDb85spKq2V9Xaqlq7dOnSET6SJOmDjBIa3weuSvLxdp1hHfACsBvY1LbZBDzWlncD\nG9sdUasYXPB+qp3KeifJVW0/N84YM72v64An2+xFkjQGi2c7sKr2J9kFfAc4BjwDbAd+AtiZZDPw\nKnBD2/5Akp3A8237W6vq/ba7W4D7gXOBJ9oD4F7gwSSTwFEGd19JksZk1qEBUFW3AbfNKL/HYNZx\nou23AdtOUJ8A1pyg/i5w/Sg9SpLmjt8IlyR1MzQkSd0MDUlSN0NDktRtpAvhkjRfVm55/ENt/8rt\n15ymTs5uzjQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS\n1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUbaTQSPLJJLuSfDfJC0l+LskF\nSfYkeak9LxnafmuSySQvJrl6qH5FkmfburuSpNXPSfJoq+9PsnKUfiVJoxl1pvGnwN9W1U8BPwO8\nAGwB9lbVamBve02Sy4CNwOXAeuDuJIvafu4BbgJWt8f6Vt8MvFVVlwJ3AneM2K8kaQSzDo0k5wO/\nANwLUFU/qKp/ATYAO9pmO4Br2/IG4JGqeq+qXgYmgSuTXAycV1X7qqqAB2aMmd7XLmDd9CxEkjT/\nRplprAKmgD9P8kySryX5BLCsqg63bV4HlrXl5cBrQ+MPttrytjyzftyYqjoGvA1cOELPkqQRjBIa\ni4GfBe6pqk8D/0o7FTWtzRxqhPfokuTmJBNJJqampk7320nSWWuU0DgIHKyq/e31LgYh8kY75UR7\nPtLWHwIuGRq/otUOteWZ9ePGJFkMnA+8ObORqtpeVWurau3SpUtH+EiSpA8y69CoqteB15J8qpXW\nAc8Du4FNrbYJeKwt7wY2tjuiVjG44P1UO5X1TpKr2vWKG2eMmd7XdcCTbfYiSRqDxSOO/y3goSQ/\nDnwP+FUGQbQzyWbgVeAGgKo6kGQng2A5BtxaVe+3/dwC3A+cCzzRHjC4yP5gkkngKIO7ryRJYzJS\naFTV3wNrT7Bq3Um23wZsO0F9Alhzgvq7wPWj9ChJmjt+I1yS1M3QkCR1MzQkSd0MDUlSN0NDktTN\n0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktRt\n1D/3KklnrZVbHv9Q279y+zWnqZP540xDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3UYO\njSSLkjyT5K/b6wuS7EnyUnteMrTt1iSTSV5McvVQ/Yokz7Z1dyVJq5+T5NFW359k5aj9SpJmby5m\nGl8BXhh6vQXYW1Wrgb3tNUkuAzYClwPrgbuTLGpj7gFuAla3x/pW3wy8VVWXAncCd8xBv5KkWRop\nNJKsAK4BvjZU3gDsaMs7gGuH6o9U1XtV9TIwCVyZ5GLgvKraV1UFPDBjzPS+dgHrpmchkqT5N+pM\n40+ArwL/MVRbVlWH2/LrwLK2vBx4bWi7g622vC3PrB83pqqOAW8DF85sIsnNSSaSTExNTY30gSRJ\nJzfr0EjyBeBIVT19sm3azKFm+x69qmp7Va2tqrVLly493W8nSWetUX6w8LPAF5P8L+BjwHlJ/gJ4\nI8nFVXW4nXo60rY/BFwyNH5Fqx1qyzPrw2MOJlkMnA+8OULPkqQRzHqmUVVbq2pFVa1kcIH7yar6\nMrAb2NQ22wQ81pZ3AxvbHVGrGFzwfqqdynonyVXtesWNM8ZM7+u69h6nfeYiSTqx0/HT6LcDO5Ns\nBl4FbgCoqgNJdgLPA8eAW6vq/TbmFuB+4FzgifYAuBd4MMkkcJRBOEmSxmROQqOq/g74u7b8JrDu\nJNttA7adoD4BrDlB/V3g+rnoUZI0Or8RLknqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6G\nhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6nY6/tyrNJKVWx7/\nUNu/cvs1p6kTSTM505AkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3WYdGkkuSfJ/kzyf5ECSr7T6\nBUn2JHmpPS8ZGrM1yWSSF5NcPVS/Ismzbd1dSdLq5yR5tNX3J1k5+48qSRrVKDONY8D/rqrLgKuA\nW5NcBmwB9lbVamBve01btxG4HFgP3J1kUdvXPcBNwOr2WN/qm4G3qupS4E7gjhH6lSSNaNahUVWH\nq+o7bfn/Ay8Ay4ENwI622Q7g2ra8AXikqt6rqpeBSeDKJBcD51XVvqoq4IEZY6b3tQtYNz0LkSTN\nvzm5ptFOG30a2A8sq6rDbdXrwLK2vBx4bWjYwVZb3pZn1o8bU1XHgLeBC+eiZ0nShzdyaCT5CeAv\ngd+pqneG17WZQ436Hh093JxkIsnE1NTU6X47STprjfTbU0l+jEFgPFRVX2/lN5JcXFWH26mnI61+\nCLhkaPiKVjvUlmfWh8ccTLIYOB94c2YfVbUd2A6wdu3a0x5SkjQfFuLvsI1y91SAe4EXqur/DK3a\nDWxqy5uAx4bqG9sdUasYXPB+qp3KeifJVW2fN84YM72v64An2+xFkjQGo8w0Pgv8MvBskr9vtd8D\nbgd2JtkMvArcAFBVB5LsBJ5ncOfVrVX1fht3C3A/cC7wRHvAIJQeTDIJHGVw95UkaUxmHRpV9f+A\nk93JtO4kY7YB205QnwDWnKD+LnD9bHuUJM0tvxEuSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZ\nGpKkboaGJKmboSFJ6jbSDxZ+FC3EHwiTpIXCmYYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZo\nSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRu/mCh/JFGSd2caUiSup0RoZFkfZIXk0wm2TLufiTp\nbLXgQyPJIuDPgP8JXAZ8Kcll4+1Kks5OCz40gCuByar6XlX9AHgE2DDmniTprHQmXAhfDrw29Pog\n8Jkx9TIyLzpLOpOlqsbdwwdKch2wvqp+vb3+ZeAzVfWbQ9vcDNzcXn4KeHHeG51bFwH/PO4mFhCP\nx/E8Hj/ksTjeKMfjv1fV0lNtdCbMNA4Blwy9XtFq/6WqtgPb57Op0ynJRFWtHXcfC4XH43gejx/y\nWBxvPo7HmXBN49vA6iSrkvw4sBHYPeaeJOmstOBnGlV1LMlvAt8AFgH3VdWBMbclSWelBR8aAFX1\nN8DfjLuPefSROdU2Rzwex/N4/JDH4nin/Xgs+AvhkqSF40y4piFJWiAMjQUoyaIkzyT563H3Mm5J\nPplkV5LvJnkhyc+Nu6dxSfK7SQ4keS7Jw0k+Nu6e5lOS+5IcSfLcUO2CJHuSvNSel4yzx/l0kuPx\nR+3fyj8k+askn5zr9zU0FqavAC+Mu4kF4k+Bv62qnwJ+hrP0uCRZDvw2sLaq1jC4KWTjeLuad/cD\n62fUtgB7q2o1sLe9Plvcz48ejz3Amqr6aeAfga1z/aaGxgKTZAVwDfC1cfcybknOB34BuBegqn5Q\nVf8y3q7GajFwbpLFwMeBfxpzP/Oqqr4FHJ1R3gDsaMs7gGvntakxOtHxqKpvVtWx9nIfg++1zSlD\nY+H5E+CrwH+Mu5EFYBUwBfx5O133tSSfGHdT41BVh4A/Br4PHAberqpvjrerBWFZVR1uy68Dy8bZ\nzALza8ATc71TQ2MBSfIF4EhVPT3uXhaIxcDPAvdU1aeBf+XsOv3wX9q5+g0MgvQngU8k+fJ4u1pY\nanArqLeDAkl+HzgGPDTX+zY0FpbPAl9M8gqDX/P9H0n+YrwtjdVB4GBV7W+vdzEIkbPRLwIvV9VU\nVf078HXg58fc00LwRpKLAdrzkTH3M3ZJfgX4AvBLdRq+U2FoLCBVtbWqVlTVSgYXOZ+sqrP2f5NV\n9TrwWpJPtdI64PkxtjRO3weuSvLxJGFwLM7KmwJm2A1sasubgMfG2MvYJVnP4PT2F6vq307He5wR\n3wjXWe23gIfa7459D/jVMfczFlW1P8ku4DsMTjs8w1n2begkDwOfAy5KchC4Dbgd2JlkM/AqcMP4\nOpxfJzkeW4FzgD2D/1uwr6p+Y07f12+ES5J6eXpKktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUz\nNCRJ3QwNSVK3/wTr7ZjnYFP11gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1801a50f3c8>"
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(list(map(len,target_seqs)),bins=25);\n",
    "\n",
    "# Truncate names longer than MAX_LEN characters. This can be changed\n",
    "MAX_LEN = min([150,max(list(map(len, target_seqs)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 13,
=======
   "execution_count": 11,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CerMemory(lasagne.layers.Layer):\n",
    "    def __init__(self, incoming, memory_shape, K=lasagne.init.Orthogonal(), V=lasagne.init.GlorotUniform(), **kwargs):\n",
    "        super(CerMemory, self).__init__(incoming, **kwargs)\n",
    "        self.query_shape = self.input_shape[1]\n",
    "        self.memory_size = memory_shape[0]\n",
    "        self.value_size = memory_shape[1]        \n",
    "        self.K = self.add_param(K, (self.query_shape, self.memory_size), name='K')\n",
    "        self.V = self.add_param(V, (self.memory_size, self.value_size), name='V')\n",
    "        print('Output shape: {}'.format( ('None', self.value_size)))\n",
    "        \n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        k = self.K / T.sqrt(T.sqr(self.K).sum(axis=0)).reshape(self.K.shape[1], 1)\n",
    "        weights =  T.dot(input, k)\n",
    "        return T.dot(weights, self.V)\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.value_size)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 14,
=======
   "execution_count": 12,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CerMemoryPD(lasagne.layers.Layer):\n",
    "    def __init__(self, incoming, memory_shape, V, K=lasagne.init.Orthogonal(), **kwargs):\n",
    "        super(CerMemoryPD, self).__init__(incoming, **kwargs)\n",
    "        self.query_shape = self.input_shape[1]\n",
    "        self.memory_size = memory_shape[0]\n",
    "        self.value_size = memory_shape[1]        \n",
    "        self.K = self.add_param(K, (self.query_shape, self.memory_size), name='K')\n",
    "        self.V = V\n",
    "        print('Output shape: {}'.format( ('None', self.value_size)))\n",
    "        \n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        k = self.K / T.sqrt(T.sqr(self.K).sum(axis=0)).reshape(self.K.shape[1], 1)\n",
    "        weights =  T.dot(input, k)\n",
    "        return T.dot(weights, self.V)\n",
    "    \n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0], self.value_size)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 15,
=======
   "execution_count": 13,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EvcNormalizer(lasagne.layers.Layer):\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        return (input.T / T.sqrt(T.sqr(input).sum(axis=1)).reshape(input.shape[0], 1)).T"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 16,
=======
   "execution_count": 14,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('token sequence', 'int32')\n",
    "output_sequence = T.matrix('target target_letters', 'int32')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 23,
=======
   "execution_count": 15,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bazal_model(query_size, memory_shape, hidden_size, K_init=None, V_init=None,\\\n",
    "                memory_benchmark=False, bidir_features=False, features_pass=False):\n",
    "\n",
    "    ##ENCODER\n",
    "    l_in = InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "    l_mask = InputLayer(shape=(None, None),input_var=T.neq(input_sequence,-1)) \n",
    "\n",
    "\n",
    "    l_emb = non_trainable(EmbeddingLayer(l_in, len(source_letters),  len(source_letters), W=np.diag(np.ones(len(source_letters), dtype='float32'))))\n",
    "\n",
    "    features = LSTMLayer(l_emb, hidden_size, only_return_final=True, mask_input=l_mask)\n",
    "    features_backward = LSTMLayer(l_emb, hidden_size, only_return_final=True, mask_input=l_mask, backwards=True)\n",
    "    if bidir_features:\n",
    "        features = ConcatLayer([features, features_backward])\n",
    "    \n",
    "    if not memory_benchmark:\n",
    "        ## QUERY BUILDER\n",
    "        query = DenseLayer(features, query_size, nonlinearity=None)\n",
    "        #query = EvcNormalizer(query)\n",
    "        ## Memory\n",
    "        if V_init is not None:\n",
    "            memory = non_trainable(CerMemory(query, memory_shape, K_init, V_init))\n",
    "        else:\n",
    "            memory = CerMemory(query, memory_shape)\n",
    "    else:\n",
    "        memory = DenseLayer(DenseLayer(features, QUERY_SIZE), QUERY_SIZE)\n",
    "    \n",
    "    if features_pass:\n",
    "        to_decode = ConcatLayer([features, memory])\n",
    "    else:\n",
    "        to_decode = memory\n",
    "        \n",
    "    ##DECODER\n",
    "    dec_in = InputLayer(shape=(None, None),input_var=output_sequence)\n",
    "    dec_mask = InputLayer(shape=(None, None),input_var=T.neq(output_sequence,-1))\n",
    "\n",
    "    dec_emb = non_trainable(EmbeddingLayer(dec_in, len(target_letters), len(target_letters), W=np.diag(np.ones(len(target_letters), dtype='float32'))))\n",
    "    dec_rnn = LSTMLayer(dec_emb, num_units=to_decode.output_shape[-1], cell_init=to_decode, mask_input=dec_mask)\n",
    "    # WARNING! if it's lstm use cell_init, not hid_init\n",
    "\n",
    "\n",
    "    #flatten batch and time to be compatible with feedforward layers (will un-flatten later)\n",
    "    dec_rnn_flat = reshape(dec_rnn, (-1,dec_rnn.output_shape[-1]))\n",
    "\n",
    "    l_out = DenseLayer(dec_rnn_flat, len(target_letters), nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    return l_out, memory"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 24,
=======
<<<<<<< HEAD:notebooks/CerMemory.ipynb
   "execution_count": 16,
=======
   "execution_count": 9,
>>>>>>> 709000a4bf40ec55cefec24a29613c5834b9e450:CerMemory.ipynb
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handle_model(nn, learning_rate_init=0.001):\n",
    "    # Model weights\n",
    "    \n",
    "    weights = get_all_params(nn)\n",
    "    network_output = get_output(nn)\n",
    "    network_output = network_output.reshape([output_sequence.shape[0],\\\n",
    "                                         output_sequence.shape[1], -1])\n",
    "    predictions_flat = network_output[:,:-1,:].reshape([-1,len(target_letters)])\n",
    "    targets = output_sequence[:,1:].ravel()\n",
    "\n",
    "    #do not count loss for '-1' tokens\n",
    "    mask = T.nonzero(T.neq(targets,-1))\n",
    "\n",
    "    loss = lasagne.objectives.categorical_crossentropy(predictions_flat[mask], targets[mask]).mean()\n",
    "    lr = theano.shared(learning_rate_init)\n",
    "    updates = lasagne.updates.adam(loss, weights, learning_rate=lr)\n",
    "    #training\n",
    "    train = theano.function([input_sequence, output_sequence], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "    #computing loss without training\n",
    "    compute_cost = theano.function([input_sequence, output_sequence], loss, allow_input_downcast=True)\n",
    "    #compile the function that computes probabilities for next token given previous text.\n",
    "\n",
    "    last_probas =network_output[:, -1]\n",
    "\n",
    "    probs = theano.function([input_sequence, output_sequence], last_probas)\n",
    "    return train, compute_cost, probs, lr"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 25,
=======
   "execution_count": 17,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QUERY_SIZE = 100\n",
    "MEMORY_SHAPE = (100, 64) # memory_size x value_size\n",
    "HIDDEN_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 26,
=======
<<<<<<< HEAD:notebooks/CerMemory.ipynb
   "execution_count": 18,
=======
   "execution_count": 292,
>>>>>>> 709000a4bf40ec55cefec24a29613c5834b9e450:CerMemory.ipynb
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#V_init = np.zeros((1000, 1000))\n",
    "#for i in range(1000):\n",
    "#    for j in range(1000):\n",
    "#        V_init[i, j] = float(i*j) / 10 ** 6\n",
    "#V_init = V_init.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": 27,
=======
   "execution_count": 19,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: ('None', 64)\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD:CerMemory.ipynb
    "l_out, memory = bazal_model(QUERY_SIZE, MEMORY_SHAPE, HIDDEN_SIZE, V_init=None, features_pass=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float32'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theano.config.floatX "
=======
<<<<<<< HEAD:notebooks/CerMemory.ipynb
    "l_out, memory = bazal_model(QUERY_SIZE, MEMORY_SHAPE, HIDDEN_SIZE, features_pass=False)"
=======
    "l_out, memory = bazal_model(QUERY_SIZE, MEMORY_SHAPE, HIDDEN_SIZE, V_init=None, features_pass=True)"
>>>>>>> 709000a4bf40ec55cefec24a29613c5834b9e450:CerMemory.ipynb
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": null,
=======
<<<<<<< HEAD:notebooks/CerMemory.ipynb
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, compute_cost, probs = handle_model(l_out, learning_rate=0.0001)"
=======
   "execution_count": 294,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
<<<<<<< HEAD:CerMemory.ipynb
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('An update must have the same type as the original shared variable (shared_var=W, shared_var.type=CudaNdarrayType(float32, matrix), update_val=Elemwise{sub,no_inplace}.0, update_val.type=TensorType(float64, matrix)).', 'If the difference is related to the broadcast pattern, you can call the tensor.unbroadcast(var, axis_to_unbroadcast[, ...]) function to remove broadcastable dimensions.')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-d9f6dac6c287>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-73a0100b9e3e>\u001b[0m in \u001b[0;36mhandle_model\u001b[1;34m(nn, learning_rate_init)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m#training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_sequence\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#computing loss without training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\etumanov\\AppData\\Local\\Continuum\\Anaconda2\\envs\\facial-animation\\lib\\site-packages\\theano\\compile\\function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    318\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\etumanov\\AppData\\Local\\Continuum\\Anaconda2\\envs\\facial-animation\\lib\\site-packages\\theano\\compile\\pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    440\u001b[0m                                          \u001b[0mrebuild_strict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrebuild_strict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                                          \u001b[0mcopy_inputs_over\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                                          no_default_updates=no_default_updates)\n\u001b[0m\u001b[0;32m    443\u001b[0m     \u001b[1;31m# extracting the arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m     \u001b[0minput_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcloned_extended_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_stuff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_vars\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\etumanov\\AppData\\Local\\Continuum\\Anaconda2\\envs\\facial-animation\\lib\\site-packages\\theano\\compile\\pfunc.pyc\u001b[0m in \u001b[0;36mrebuild_collect_shared\u001b[1;34m(outputs, inputs, replace, updates, rebuild_strict, copy_inputs_over, no_default_updates)\u001b[0m\n\u001b[0;32m    205\u001b[0m                        ' function to remove broadcastable dimensions.')\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_sug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mupdate_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstore_into\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('An update must have the same type as the original shared variable (shared_var=W, shared_var.type=CudaNdarrayType(float32, matrix), update_val=Elemwise{sub,no_inplace}.0, update_val.type=TensorType(float64, matrix)).', 'If the difference is related to the broadcast pattern, you can call the tensor.unbroadcast(var, axis_to_unbroadcast[, ...]) function to remove broadcastable dimensions.')"
     ]
    }
   ],
   "source": [
    "train, compute_cost, probs, lr = handle_model(l_out, learning_rate_init=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(range(100)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "source": [
    "train, compute_cost, probs, lr = handle_model(l_out, learning_rate_init=0.001)"
>>>>>>> 709000a4bf40ec55cefec24a29613c5834b9e450:CerMemory.ipynb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:17<00:00, 64.46it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 286.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train average loss = 0.5361390013197174\n",
      "Epoch 0 val average loss = 0.5437770782621573\n",
      "84*994 : 83496  |  83496\n",
      "945*67080 : 63382600  |  63390600\n",
      "53*4336 : 230208  |  229808\n",
      "2*13463 : 26726  |  26926\n",
      "37571*6779 : 254696329  |  254693809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:17<00:00, 64.57it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 288.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train average loss = 0.5353691331474226\n",
      "Epoch 1 val average loss = 0.5391225971553703\n",
      "5764*686 : 3953584  |  3954104\n",
      "7253*3832 : 27793396  |  27793496\n",
      "465*84089 : 39025985  |  39101385\n",
      "79464*1572 : 124859728  |  124917408\n",
      "90200*0 : 0  |  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:17<00:00, 64.49it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 287.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train average loss = 0.5351185118524291\n",
      "Epoch 2 val average loss = 0.5375298221823034\n",
      "6230*53 : 329790  |  330190\n",
      "47*47783 : 2246561  |  2245801\n",
      "14987*85 : 1273095  |  1273895\n",
      "95564*8 : 766112  |  764512\n",
      "614*46 : 28244  |  28244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:17<00:00, 64.19it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 285.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train average loss = 0.5338469572302125\n",
      "Epoch 3 val average loss = 0.5427634884967435\n",
      "5240*4113 : 21532120  |  21552120\n",
      "92*4414 : 405968  |  406088\n",
      "68215*6551 : 446992865  |  446876465\n",
      "18525*7 : 129675  |  129675\n",
      "4412*341 : 1505732  |  1504492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:17<00:00, 64.34it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 287.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train average loss = 0.5323840728130949\n",
      "Epoch 4 val average loss = 0.540024148595564\n",
      "7*0 : 0  |  0\n",
      "31075*38 : 1178850  |  1180850\n",
      "46466*54 : 2512524  |  2509164\n",
      "39817*4 : 160068  |  159268\n",
      "9647*317 : 3060679  |  3058099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:17<00:00, 64.27it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 283.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train average loss = 0.5310312994579751\n",
      "Epoch 5 val average loss = 0.541249449489151\n",
      "818*26875 : 21962950  |  21983750\n",
      "5243*51 : 267293  |  267393\n",
      "5*4024 : 20120  |  20120\n",
      "6049*70 : 422030  |  423430\n",
      "6738*57 : 383946  |  384066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:17<00:00, 64.23it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 284.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 train average loss = 0.5310268537590821\n",
      "Epoch 6 val average loss = 0.5352706271453627\n",
      "93924*9 : 844116  |  845316\n",
      "35*5458 : 190730  |  191030\n",
      "1092*2417 : 2633884  |  2639364\n",
      "66411*4 : 265644  |  265644\n",
      "13573*1123 : 15090739  |  15242479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:17<00:00, 64.20it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 285.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 train average loss = 0.5314517068097553\n",
      "Epoch 7 val average loss = 0.5413760114877391\n",
      "79*3947 : 311933  |  311813\n",
      "56*21949 : 1224824  |  1229144\n",
      "7503*2650 : 19837950  |  19882950\n",
      "6*33468 : 200848  |  200808\n",
      "38162*9432 : 360283544  |  359943984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:17<00:00, 64.30it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 285.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train average loss = 0.5296482031219082\n",
      "Epoch 8 val average loss = 0.537969451540883\n",
      "54675*103 : 5637525  |  5631525\n",
      "80970*7061 : 572012370  |  571729170\n",
      "6*1409 : 8454  |  8454\n",
      "98*807 : 79086  |  79086\n",
      "61*5296 : 322976  |  323056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:17<00:00, 64.27it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 286.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 train average loss = 0.5303476442396575\n",
      "Epoch 9 val average loss = 0.5318305438693759\n",
      "601*420 : 252420  |  252420\n",
      "28536*4384 : 125300704  |  125101824\n",
      "54236*85 : 4599060  |  4610060\n",
      "5308*55 : 292140  |  291940\n",
      "84567*131 : 11090977  |  11078277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:17<00:00, 64.17it/s]\n",
      "100%|██████████| 500/500 [00:01<00:00, 284.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 train average loss = 0.5274935747329159\n",
      "Epoch 10 val average loss = 0.5361649949467056\n",
      "96*6112 : 587512  |  586752\n",
      "5062*81 : 410022  |  410022\n",
      "789*81 : 63909  |  63909\n",
      "25372*10203 : 260644356  |  258870516\n",
      "50*200 : 10000  |  10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1924/5000 [00:30<00:48, 63.78it/s]"
     ]
    }
   ],
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "source": [
    "#total N iterations\n",
    "n_epochs=300\n",
    "\n",
    "# how many minibatches are there in the epoch \n",
    "train_batches_per_epoch = 5000\n",
    "val_batches_per_epoch = 500\n",
    "\n",
    "#how many training sequences are processed in a single function call\n",
    "batch_size=64\n",
    "\n",
    "\n",
    "train_source_seqs, val_source_seqs, train_target_seqs, val_target_seqs = train_test_split(source_seqs, target_seqs,\\\n",
    "                                                                                          test_size=0.15, random_state=42)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    try:\n",
    "\n",
    "        train_avg_cost = 0;\n",
    "        val_avg_cost = 0;\n",
    "        if epoch != 0 and epoch % 30==0:\n",
    "            lr.set_value(lr.get_value() / 10.)\n",
    "        \n",
    "        for _ in tqdm.tqdm(range(train_batches_per_epoch)):\n",
    "            x,y = sample_batch(train_source_seqs, source_letter_to_ix, train_target_seqs, target_letter_to_ix, batch_size)\n",
    "            train_avg_cost += train(x, y).mean()\n",
    "        \n",
    "        for _ in tqdm.tqdm(range(val_batches_per_epoch)):\n",
    "            x,y = sample_batch(val_source_seqs, source_letter_to_ix, val_target_seqs, target_letter_to_ix, batch_size)\n",
    "            val_avg_cost += compute_cost(x, y).mean()\n",
    "\n",
    "        print(\"Epoch {} train average loss = {}\".format(epoch, train_avg_cost / train_batches_per_epoch))\n",
    "        print(\"Epoch {} val average loss = {}\".format(epoch, val_avg_cost / val_batches_per_epoch))\n",
    "        \n",
    "        for i in range(5):\n",
    "            ind = np.random.randint(len(val_source_seqs))\n",
    "            print (val_source_seqs[ind],':', ''.join(generate_output(val_source_seqs[ind], probs, target_letters, target_letter_to_ix, \\\n",
    "                                                             source_letter_to_ix, sample=True)[1:-1]),' | ', ''.join(val_target_seqs[ind][1:-1]))\n",
    "\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": null,
=======
   "execution_count": 22,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#K_prod = np.array(memory.K.eval())\n",
    "#V_prod = np.array(memory.V.eval())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:CerMemory.ipynb
   "execution_count": null,
=======
   "execution_count": 23,
>>>>>>> 6caecee3b68fd8f5eda953679e599fc90f485047:notebooks/CerMemory.ipynb
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.save('./zoo/prod_memory_K_afterINFepochs.npy', K_prod)\n",
    "#np.save('./zoo/prod_memory_V_afterINFepochs.npy', V_prod)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:notebooks/CerMemory.ipynb
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['977*88', '8*73963', '0*227', ..., '265*9900', '4*8837',\n",
       "       '91149*73480'],\n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_source_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4*50657', '202228')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_source_seqs[ind], ''.join(generate_output(val_source_seqs[ind], probs, target_letters, target_letter_to_ix, \\\n",
    "                                                             source_letter_to_ix, sample=True)[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
=======
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
>>>>>>> 709000a4bf40ec55cefec24a29613c5834b9e450:CerMemory.ipynb
   "outputs": [],
   "source": [
    "test_seqs = [seq for seq in val_source_seqs if len(seq.split('*')[0]) <4 and len(seq.split('*')[1]) <4]\n",
    "test_target_seqs = [t for seq, t in zip(val_source_seqs,val_target_seqs) if len(seq.split('*')[0]) <4 and len(seq.split('*')[1]) <4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12369/12369 [02:02<00:00, 100.77it/s]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "true_count = 0\n",
    "for i in tqdm.tqdm(range(len(test_seqs))):\n",
    "    true_count+= int(test_target_seqs[i] == generate_output(test_seqs[i], probs, target_letters, target_letter_to_ix, \\\n",
    "                                                             source_letter_to_ix, sample=True))\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5381194922790848"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(true_count) /count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
